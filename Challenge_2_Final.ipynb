{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 Tutorial\n",
    "\n",
    "Our characters have gathered a collection of text files from the internet using the `la eterna` keyword and they want to get a general understanding of the various topics that are present in these articles. The data science term for this task is Topic Modeling and there are many different techniques to create and visualize topic models. This tutorial will focus on a specific method called Latent Dirichlet Allocation (LDA) and will present some different methods of visualizing and exploring the topics that it generates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Ib6jSQY3BT5",
    "outputId": "7f98764b-67fd-4699-f454-01eb2e2cf89f"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# WordCloud \u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwordcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WordCloud, STOPWORDS\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# NLTK Stop words\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import re\n",
    "import os\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# WordCloud \n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "# NLTK Stop words\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Gensim\n",
    "import gensim, spacy, logging, warnings\n",
    "import en_core_web_sm\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "\"\"\"\n",
    "# Sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Pyldavis \n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import pyLDAvis.sklearn\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: You will have to run `python -m spacy download en_core_web_sm` to download (you cant pip install it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nnzvXcr53LDi"
   },
   "outputs": [],
   "source": [
    "project_dir = 'challenge2-articles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uL1xQy9eMkWA"
   },
   "outputs": [],
   "source": [
    "# gets files from article directory\n",
    "fns = []\n",
    "for file_name in os.listdir(project_dir):\n",
    "    if file_name.endswith('.txt'):\n",
    "        fns.append(os.path.join(project_dir,file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this opens the txt files and appends the text files to the text dataframe \n",
    "df_txt = pd.DataFrame(columns=['fn', 'txt'])\n",
    "for idx, fn in enumerate(fns):  \n",
    "    print(fn)\n",
    "    x = open(fn, mode=\"r\", encoding=\"utf-8\")\n",
    "    x = x.read()  \n",
    "    _df_txt = pd.DataFrame([[idx, x]],columns=['fn', 'txt'])\n",
    "    df_txt = df_txt.append(_df_txt)\n",
    "df_txt = df_txt.reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Text Files\n",
    "Inspired by https://www.machinelearningplus.com/nlp/topic-modeling-visualization-how-to-present-results-lda-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6rb9erhC3Q8h"
   },
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sent in sentences:\n",
    "        sent = re.sub(r'\\s+', ' ', sent)  # remove newline chars\n",
    "        sent = re.sub(r\"\\'\", \"\", sent)  # remove single quotes\n",
    "        sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
    "        yield(sent)   \n",
    "\n",
    "def process_words(data_words, stop_words=stop_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"Remove Stopwords, Form Bigrams, Trigrams and Lemmatization\"\"\"\n",
    "    # initialize bigram and trigram models \n",
    "    bigram = gensim.models.Phrases(data_words, min_count=5, threshold=10) # higher threshold fewer phrases.\n",
    "    trigram = gensim.models.Phrases(bigram[data_words], threshold=10)  \n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "    \n",
    "    monogram_texts = []\n",
    "    for doc in data_words:\n",
    "        doc_texts = []\n",
    "        for word in simple_preprocess(str(doc)):\n",
    "            if word not in stop_words:\n",
    "                doc_texts.append(word)\n",
    "        monogram_texts.append(doc_texts)\n",
    "    texts_with_bigram = []\n",
    "    for doc in monogram_texts:\n",
    "        texts_with_bigram.append(bigram_mod[doc])\n",
    "    texts = []\n",
    "    for doc in texts_with_bigram:\n",
    "        texts.append(trigram_mod[bigram_mod[doc]])\n",
    "    texts_out = []\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    # remove stopwords once more after lemmatization\n",
    "    texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n",
    "    return texts_out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P3gkqqTm3TJp",
    "outputId": "3eb18ac9-7707-4be3-ec4f-927b03096766"
   },
   "outputs": [],
   "source": [
    "# takes the text dataframe, extracts the sentences and breaks the sentences into words\n",
    "data = df_txt['txt'].values\n",
    "data_words = list(sent_to_words(data))   \n",
    "\n",
    "# removes stop words, forms bigrams, trigrams, lemmatizations\n",
    "texts = process_words(data_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic WordCloud Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "id": "TfhhCdZn345s",
    "outputId": "060ca125-8be2-44d6-b187-41ea86189e90"
   },
   "outputs": [],
   "source": [
    "# explore the cleaned words dataset \n",
    "wordcloud_texts = [y for x in texts for y in x]\n",
    "text_describe = pd.Series(wordcloud_texts)\n",
    "wordcloud_texts = ' '.join(wordcloud_texts)\n",
    "wordcloud = WordCloud(width=1280, height=720, background_color='white', stopwords=stop_words).generate(wordcloud_texts)\n",
    "plt.imshow(wordcloud)\n",
    "plt.title(\"Basic Word Cloud\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Initial Topic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TN9fWcM18w-Y"
   },
   "outputs": [],
   "source": [
    "# get unique IDs for words \n",
    "id2word = corpora.Dictionary(texts)\n",
    "\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "num_topics=10\n",
    "# Build LDA model\n",
    "# update_every is for iterative learning (as opposed to batch learning) \n",
    "# chunksize is amount of data to use to train on each pass (using all given files)\n",
    "# passes is amount of times to pass through the corpus \n",
    "# alpha is the prior, \"symmetric\" is a 1/num_topics \n",
    "# per_word_topics returns a list of likely topics (as opposed to the top topic)\n",
    "ldamodel = (gensim\n",
    "            .models\n",
    "            .ldamodel\n",
    "            .LdaModel(corpus=corpus, id2word=id2word,\n",
    "                      num_topics=num_topics, random_state=100,\n",
    "                      update_every=1, chunksize=len(fns), \n",
    "                      passes=100, alpha='symmetric', \n",
    "                      per_word_topics=True))\n",
    "\n",
    "# passes data through the LDA model, identifies the topic of each sentence \n",
    "df_topics = pd.DataFrame()\n",
    "for i, row_list in enumerate(ldamodel[corpus]):\n",
    "    row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "    # print(row)\n",
    "    row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "    # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "    for j, (topic_num, prop_topic) in enumerate(row):\n",
    "        if j == 0:  # => dominant topic\n",
    "            wp = ldamodel.show_topic(topic_num)\n",
    "            topic_keywords = \", \".join([word for word, prop in wp])\n",
    "            df_topics = df_topics.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "        else:\n",
    "            break\n",
    "df_topics.columns = ['dominant_topic', 'contribution%', 'keywords']\n",
    "df_topics['text'] = pd.Series(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_top_words = {}\n",
    "for topic_num in range(num_topics):\n",
    "    word_list = [row[0] for row in ldamodel.show_topic(topic_num)]\n",
    "    topic_model_top_words[f\"topic_{topic_num}\"] = word_list\n",
    "pd.DataFrame(topic_model_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for best number of Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def build_topic_model(num_topics,corpus,id2word):\n",
    "    LDA_model = (gensim\n",
    "                .models\n",
    "                .ldamodel\n",
    "                .LdaModel(corpus=corpus, id2word=id2word,\n",
    "                          num_topics=num_topics, random_state=1842,\n",
    "                          update_every=1, chunksize=len(fns), \n",
    "                          passes=4000, alpha='symmetric', \n",
    "                          per_word_topics=True))\n",
    "    return LDA_model\n",
    "def plot_wordcloud_from_lda(lda,num_topics):\n",
    "    if num_topics == 2:\n",
    "        fig, axes = plt.subplots(1, 2)\n",
    "        for i in range(num_topics):\n",
    "            word_weights = lda.show_topic(i)\n",
    "            wordcloud = WordCloud(background_color='white').fit_words(dict(word_weights))\n",
    "            axes[i].imshow(wordcloud)\n",
    "            axes[i].set_title(f\"Topic {i}\")\n",
    "            axes[i].axis(\"off\")\n",
    "        fig.suptitle(f\"LDA with {num_topics} Topics\", fontsize=20)\n",
    "        plt.tight_layout(pad = 0)\n",
    "        plt.show()\n",
    "    else:\n",
    "        rows = math.ceil(num_topics / 2)\n",
    "        fig, axes = plt.subplots(rows, 2)\n",
    "        for i in range(num_topics):\n",
    "            word_weights = lda.show_topic(i)\n",
    "            wordcloud = WordCloud(background_color='white').fit_words(dict(word_weights))\n",
    "            x = i // 2\n",
    "            y = i % 2\n",
    "            axes[x,y].imshow(wordcloud)\n",
    "            axes[x,y].set_title(f\"Topic {i}\")\n",
    "            axes[x,y].axis(\"off\")\n",
    "        if num_topics % 2:\n",
    "            x = num_topics // 2\n",
    "            y = 1\n",
    "            axes[x,y].axis(\"off\")\n",
    "        plt.tight_layout(pad = 0)\n",
    "        fig.suptitle(f\"LDA with {num_topics} Topics\", fontsize=20)\n",
    "        fig.subplots_adjust(top=0.85)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_models = []\n",
    "for i in range(2,11):\n",
    "    model = build_topic_model(i,corpus,id2word)\n",
    "    LDA_models.append(model)\n",
    "    model_name = os.path.join(\"models\",f\"la_eterna_topic_model-{i}.lda\")\n",
    "    model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models from saved files \n",
    "This step is only needed if you are picking back up later and dont want to wait to rerun the previous gensim models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_models = []\n",
    "for i in range(2,11):\n",
    "    model_name = os.path.join(\"models\",f\"la_eterna_topic_model-{i}.lda\")\n",
    "    model = gensim.models.ldamodel.LdaModel.load(model_name)\n",
    "    LDA_models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Topic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 2\n",
    "for model in LDA_models:\n",
    "    plot_wordcloud_from_lda(model,count)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Areas of Improvement\n",
    "\n",
    "### pyLDAvis\n",
    "\n",
    "pyLDAvis Tutorials:\n",
    "* https://neptune.ai/blog/pyldavis-topic-modelling-exploration-tool-that-every-nlp-data-scientist-should-know\n",
    "* https://nbviewer.org/github/bmabey/pyLDAvis/blob/master/notebooks/pyLDAvis_overview.ipynb\n",
    "\n",
    "Research Papers:\n",
    "* http://vis.stanford.edu/files/2012-Termite-AVI.pdf\n",
    "* https://nlp.stanford.edu/events/illvi2014/papers/sievert-illvi2014.pdf\n",
    "\n",
    "### Sklearn Implementation\n",
    "Inspired by: https://nbviewer.org/github/bmabey/pyLDAvis/blob/master/notebooks/sklearn.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMMNmNGuoTuew8qE70n8NhW",
   "include_colab_link": true,
   "mount_file_id": "1uFtiLjzta7OFAbmFwYRBNZq7nKTrl_0e",
   "name": "challenge2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
